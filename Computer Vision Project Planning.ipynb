{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1752164689791,
     "user": {
      "displayName": "Xabier Urruchua Garay",
      "userId": "18097917275269054198"
     },
     "user_tz": -240
    },
    "id": "TH0f1XVXJmiG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "#from torchvision import transforms\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from pillow_heif import register_heif_opener\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[same dog] Download: 0it [00:00, ?it/s]\n",
      "[same cat] Download: 100%|██████████| 137/137 [00:00<00:00, 6285.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9806.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9809.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9810.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9808.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9807.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9800.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9802.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9801.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9796.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9797.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9799.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9798.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9805.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9804.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9803.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9665.MOV\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9664.MOV\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9784.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9783.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9786.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9785.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9787.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9782.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9781.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9778.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9779.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9774.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9776.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9780.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9773.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9775.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9771.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9777.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9772.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9764.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9760.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9759.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9753.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9755.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9757.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9756.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9754.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9752.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9751.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9749.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9750.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9748.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9747.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9742.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9746.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9744.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9741.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9745.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9743.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9739.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9740.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9728.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9738.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9736.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9726.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9735.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9737.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9727.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9729.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9734.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9733.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9732.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9724.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9731.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9730.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9725.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9723.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9721.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9710.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9722.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9717.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9719.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9715.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9720.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9718.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9716.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9714.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9713.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9706.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9700.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9704.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9712.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9705.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9711.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9708.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9709.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9707.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9703.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9702.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9701.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9699.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9697.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9694.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9698.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9695.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9690.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9696.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9687.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9688.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9693.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9692.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9691.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9689.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9686.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9681.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9684.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9683.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9685.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9680.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9676.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9679.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9682.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9678.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9677.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9675.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9669.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9674.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9671.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9658.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9673.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9667.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9672.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9670.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9659.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9666.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9668.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9660.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9661.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9662.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9657.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9656.HEIC\n",
      "Skipping download, already exists: downloaded_data\\same cat\\IMG_9787.HEIC\n",
      "Skipping IMG_9664.MOV: frames already extracted\n",
      "Skipping IMG_9665.MOV: frames already extracted\n",
      "Google Drive same cat/dog Download and Frame extraction complete!\n",
      "Augmentation/Standardization start...\n",
      "All augmented/standardized images saved!\n"
     ]
    }
   ],
   "source": [
    "register_heif_opener()\n",
    "\n",
    "# -------- 1. Google Drive Authentication --------\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive\"]\n",
    "creds = None\n",
    "\n",
    "if os.path.exists(\"token.json\"):\n",
    "    creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            \"client_secret_676204196755-36uo6inh0emqfied3g2s0185anhbe1l5.apps.googleusercontent.com.json\", SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "with open(\"token.json\", \"w\") as token:\n",
    "    token.write(creds.to_json())\n",
    "\n",
    "try:\n",
    "    # -------- 2. Google Drive \"same cat/same dog\", Downloading images/videos --------\n",
    "    service = build(\"drive\", \"v3\", credentials=creds)\n",
    "    response = service.files().list(\n",
    "        q=\"sharedWithMe and mimeType='application/vnd.google-apps.folder' and name contains 'Capstone'\",\n",
    "        spaces=\"drive\"\n",
    "    ).execute()\n",
    "    capstone_folders = response.get('files', [])\n",
    "\n",
    "    if not capstone_folders:\n",
    "        print('No Capstone folder found.')\n",
    "        exit()\n",
    "\n",
    "    # Looking inside \"same cat\", \"same dog\"\n",
    "    children_folders = []\n",
    "    for parent in capstone_folders:\n",
    "        parent_id = parent['id']\n",
    "        response = service.files().list(\n",
    "            q=f\"'{parent_id}' in parents and mimeType='application/vnd.google-apps.folder'\",\n",
    "            spaces=\"drive\"\n",
    "        ).execute()\n",
    "        for child in response.get('files', []):\n",
    "            if child['name'] in ['same cat', 'same dog']:\n",
    "                children_folders.append(child)\n",
    "\n",
    "    if not children_folders:\n",
    "        print('No same cat or same dog folder found.')\n",
    "        exit()\n",
    "\n",
    "    for fold in children_folders:\n",
    "        fold_name = fold['name']\n",
    "        fold_id = fold['id']\n",
    "\n",
    "        # 2-1. Saving in Local Directory\n",
    "        save_img_dir = os.path.join('downloaded_data', fold_name)\n",
    "        os.makedirs(save_img_dir, exist_ok=True)\n",
    "\n",
    "        # 2-2. Downloading Images/Videos\n",
    "        response = service.files().list(\n",
    "            q=f\"'{fold_id}' in parents and (mimeType contains 'image/' or mimeType contains 'video/')\",\n",
    "            spaces='drive',\n",
    "            fields=\"files(id,name,mimeType)\",\n",
    "            pageSize=1000,\n",
    "        ).execute()\n",
    "        files = response.get('files', [])\n",
    "\n",
    "        for file in tqdm.tqdm(files, desc=f\"[{fold_name}] Download\"):\n",
    "            file_id = file['id']\n",
    "            file_name = file['name']\n",
    "            mime_type = file['mimeType']\n",
    "            local_path = os.path.join(save_img_dir, file_name)\n",
    "\n",
    "            if os.path.exists(local_path):\n",
    "                print(f\"Skipping download, already exists: {local_path}\")\n",
    "            else:\n",
    "                request = service.files().get_media(fileId=file_id)\n",
    "                fh = io.BytesIO()\n",
    "                downloader = MediaIoBaseDownload(fh, request)\n",
    "                done = False\n",
    "                while not done:\n",
    "                    status, done = downloader.next_chunk()\n",
    "                fh.seek(0)\n",
    "                with open(local_path, \"wb\") as out_f:\n",
    "                    out_f.write(fh.getvalue())\n",
    "\n",
    "        # 2-3. Extracting images every 0.25 seconds from videos\n",
    "        video_exts = ('.mov', '.mp4', '.avi', '.mkv', '.wmv', '.flv', '.webm')\n",
    "        for fname in os.listdir(save_img_dir):\n",
    "            if fname.lower().endswith(video_exts):\n",
    "                base_name = os.path.splitext(fname)[0]\n",
    "                example_frame = os.path.join(save_img_dir, f\"{base_name}_frame000000.jpg\")\n",
    "                if os.path.exists(example_frame):\n",
    "                    print(f\"Skipping {fname}: frames already extracted\")\n",
    "                    continue\n",
    "                video_path = os.path.join(save_img_dir, fname)\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                interval = int(fps * 0.25) if fps > 0 else 1\n",
    "                frame_id = 0\n",
    "                save_id = 0\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    if frame_id % max(1, interval) == 0:\n",
    "                        out_name = f\"{base_name}_frame{save_id:06d}.jpg\"\n",
    "                        out_path = os.path.join(save_img_dir, out_name)\n",
    "                        cv2.imwrite(out_path, frame)\n",
    "                        save_id += 1\n",
    "                    frame_id += 1\n",
    "                cap.release()\n",
    "                print(f\"{fname}: {save_id} frames extracted\")\n",
    "\n",
    "except HttpError as e:\n",
    "    print(\"Error: \", str(e))\n",
    "\n",
    "print(\"Google Drive same cat/dog Download and Frame extraction complete!\")\n",
    "\n",
    "# -------- 3. Standardization + Augmentation (For all images) --------\n",
    "print(\"Augmentation/Standardization start...\")\n",
    "\n",
    "# Standardization + Augmentation transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "folders = ['downloaded_data/same cat', 'downloaded_data/same dog']\n",
    "out_base = 'augmented_data'\n",
    "os.makedirs(out_base, exist_ok=True)\n",
    "img_exts = ('.jpg', '.jpeg', '.png', '.webp', '.heic')\n",
    "\n",
    "for folder in folders:\n",
    "    class_name = os.path.basename(folder)\n",
    "    out_folder = os.path.join(out_base, class_name)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    img_files = [f for f in os.listdir(folder) if f.lower().endswith(img_exts)]\n",
    "    for fname in img_files:\n",
    "        img_path = os.path.join(folder, fname)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Fail open {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Saving pictures including the original ones\n",
    "        orig_fname = f\"{os.path.splitext(fname)[0]}_orig.jpg\"\n",
    "        orig_path = os.path.join(out_folder, orig_fname)\n",
    "        img.resize((224,224)).save(orig_path)\n",
    "        # Original picture + 5 randomly standardized/augmented pictures\n",
    "        for aug_id in range(5):\n",
    "            img_aug_tensor = transform(img)\n",
    "            aug_fname = f\"{os.path.splitext(fname)[0]}_aug{aug_id:02d}.jpg\"\n",
    "            aug_path = os.path.join(out_folder, aug_fname)\n",
    "            to_img = transforms.ToPILImage()(torch.clamp(img_aug_tensor, 0, 1))\n",
    "            to_img.save(aug_path)\n",
    "\n",
    "print(\"All augmented/standardized images saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 chair, 1 book, 200.6ms\n",
      "Speed: 6.3ms preprocess, 200.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.0ms\n",
      "Speed: 1.4ms preprocess, 82.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 78.7ms\n",
      "Speed: 1.2ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 refrigerator, 86.6ms\n",
      "Speed: 1.4ms preprocess, 86.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.6ms\n",
      "Speed: 1.5ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 86.4ms\n",
      "Speed: 1.2ms preprocess, 86.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 refrigerator, 82.0ms\n",
      "Speed: 1.8ms preprocess, 82.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 129.6ms\n",
      "Speed: 1.6ms preprocess, 129.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 chairs, 94.0ms\n",
      "Speed: 1.5ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 81.2ms\n",
      "Speed: 1.2ms preprocess, 81.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 92.4ms\n",
      "Speed: 1.7ms preprocess, 92.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 158.5ms\n",
      "Speed: 2.2ms preprocess, 158.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 114.3ms\n",
      "Speed: 1.8ms preprocess, 114.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 77.0ms\n",
      "Speed: 1.6ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.4ms\n",
      "Speed: 1.2ms preprocess, 84.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 88.6ms\n",
      "Speed: 1.7ms preprocess, 88.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 book, 81.5ms\n",
      "Speed: 1.4ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 116.1ms\n",
      "Speed: 1.7ms preprocess, 116.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 109.1ms\n",
      "Speed: 2.7ms preprocess, 109.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.7ms\n",
      "Speed: 1.7ms preprocess, 100.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 99.4ms\n",
      "Speed: 3.0ms preprocess, 99.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 108.5ms\n",
      "Speed: 2.1ms preprocess, 108.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.6ms\n",
      "Speed: 1.3ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.7ms\n",
      "Speed: 2.1ms preprocess, 84.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 103.8ms\n",
      "Speed: 3.3ms preprocess, 103.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 88.7ms\n",
      "Speed: 2.2ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.1ms\n",
      "Speed: 2.1ms preprocess, 79.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.3ms\n",
      "Speed: 1.5ms preprocess, 80.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.7ms\n",
      "Speed: 1.9ms preprocess, 107.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 102.5ms\n",
      "Speed: 2.8ms preprocess, 102.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 104.2ms\n",
      "Speed: 1.9ms preprocess, 104.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 96.5ms\n",
      "Speed: 2.8ms preprocess, 96.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.7ms\n",
      "Speed: 1.5ms preprocess, 89.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 106.5ms\n",
      "Speed: 1.7ms preprocess, 106.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 116.0ms\n",
      "Speed: 1.8ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.0ms\n",
      "Speed: 1.3ms preprocess, 79.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.6ms\n",
      "Speed: 1.5ms preprocess, 147.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.4ms\n",
      "Speed: 1.6ms preprocess, 72.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.5ms\n",
      "Speed: 2.3ms preprocess, 91.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 110.1ms\n",
      "Speed: 1.5ms preprocess, 110.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 97.5ms\n",
      "Speed: 1.5ms preprocess, 97.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 87.5ms\n",
      "Speed: 1.6ms preprocess, 87.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 115.3ms\n",
      "Speed: 2.1ms preprocess, 115.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 154.2ms\n",
      "Speed: 2.5ms preprocess, 154.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 140.9ms\n",
      "Speed: 2.4ms preprocess, 140.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.5ms\n",
      "Speed: 1.7ms preprocess, 107.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.6ms\n",
      "Speed: 1.3ms preprocess, 90.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.7ms\n",
      "Speed: 1.2ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.0ms\n",
      "Speed: 3.0ms preprocess, 137.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.2ms\n",
      "Speed: 1.8ms preprocess, 100.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 136.1ms\n",
      "Speed: 2.2ms preprocess, 136.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 99.6ms\n",
      "Speed: 1.3ms preprocess, 99.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.5ms\n",
      "Speed: 1.2ms preprocess, 81.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.0ms\n",
      "Speed: 1.4ms preprocess, 88.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.7ms\n",
      "Speed: 1.6ms preprocess, 80.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.4ms\n",
      "Speed: 1.2ms preprocess, 83.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.9ms\n",
      "Speed: 1.9ms preprocess, 80.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.7ms\n",
      "Speed: 1.4ms preprocess, 93.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 101.8ms\n",
      "Speed: 1.3ms preprocess, 101.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.0ms\n",
      "Speed: 1.6ms preprocess, 93.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.9ms\n",
      "Speed: 1.4ms preprocess, 158.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.7ms\n",
      "Speed: 1.3ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.2ms\n",
      "Speed: 1.3ms preprocess, 78.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 125.1ms\n",
      "Speed: 3.4ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 182.4ms\n",
      "Speed: 2.8ms preprocess, 182.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 book, 181.7ms\n",
      "Speed: 2.3ms preprocess, 181.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 140.2ms\n",
      "Speed: 1.7ms preprocess, 140.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 194.6ms\n",
      "Speed: 2.2ms preprocess, 194.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 book, 162.2ms\n",
      "Speed: 2.0ms preprocess, 162.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 188.1ms\n",
      "Speed: 2.1ms preprocess, 188.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.4ms\n",
      "Speed: 3.3ms preprocess, 168.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 174.4ms\n",
      "Speed: 1.9ms preprocess, 174.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 182.5ms\n",
      "Speed: 2.6ms preprocess, 182.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 192.3ms\n",
      "Speed: 2.9ms preprocess, 192.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 refrigerator, 191.1ms\n",
      "Speed: 2.4ms preprocess, 191.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 194.5ms\n",
      "Speed: 2.3ms preprocess, 194.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 book, 159.2ms\n",
      "Speed: 1.5ms preprocess, 159.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 189.1ms\n",
      "Speed: 2.1ms preprocess, 189.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 208.5ms\n",
      "Speed: 2.7ms preprocess, 208.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# YOLOv8n: Already trained with cat & dog (Index 15:cat, Index 16:dog)\n",
    "# https://docs.ultralytics.com/datasets/detect/coco/#coco-pretrained-models\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "names_dict = model.model.names\n",
    "cat_id = [k for k, v in names_dict.items() if v == 'cat'][0]\n",
    "dog_id = [k for k, v in names_dict.items() if v == 'dog'][0]\n",
    "person_id = [k for k, v in names_dict.items() if v == 'person'][0]\n",
    "bear_id = [k for k, v in names_dict.items() if v == 'bear'][0]\n",
    "\n",
    "# Opening webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Utilizing YOLO model detecting (confidence level = 30%)\n",
    "    results = model.predict(frame, conf=0.3)\n",
    "\n",
    "    found_pet = False\n",
    "    reject_flag = False\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        label = model.model.names[cls]\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "        # Color\n",
    "        if label == 'cat':\n",
    "            color = (0, 255, 0)    # Green\n",
    "            found_pet = True\n",
    "        elif label == 'dog':\n",
    "            color = (255, 0, 0)    # Blue\n",
    "            found_pet = True\n",
    "        elif label == 'person':\n",
    "            color = (0, 0, 255)    # Red\n",
    "            reject_flag = True\n",
    "        elif label == 'bear':\n",
    "            color = (0, 0, 255)  # Red\n",
    "            reject_flag = True\n",
    "        else:\n",
    "            color = (0, 255, 255)    # Yellow\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, label, (x1, y1+30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    # Decision Logics\n",
    "    if reject_flag:\n",
    "        status = \"REJECT (person or bear in screen!)\"\n",
    "    elif found_pet:\n",
    "        status = \"STAGE 2 (only pet present)\"\n",
    "        # stage2(frame)\n",
    "\n",
    "        '''\n",
    "        We can have our Stage 2 logics here\n",
    "        '''\n",
    "        \n",
    "    else:\n",
    "        status = \"EMPTY or only allowed objects in screen\"\n",
    "\n",
    "    # Status on Screen\n",
    "    cv2.putText(frame, status, (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,0,0), 3)\n",
    "    cv2.putText(frame, status, (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,255), 2)\n",
    "\n",
    "    cv2.imshow('Pet Gate', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same cat: {'.heic': 134, '.mov': 2, '.jpg': 88}\n",
      "random dogs: {'.jpg': 1000}\n",
      "random cats: {'.png': 104, '.webp': 1, '.jpg': 3}\n"
     ]
    }
   ],
   "source": [
    "# Checking types of images/videos in folders\n",
    "#def list_file_types(folder):\n",
    "#    file_count = {}\n",
    "#    for fname in os.listdir(folder):\n",
    "#        ext = os.path.splitext(fname)[-1].lower()\n",
    "#        file_count[ext] = file_count.get(ext, 0) + 1\n",
    "#    return file_count\n",
    "\n",
    "#print(\"same cat:\", list_file_types('downloaded_data/same cat'))\n",
    "#print(\"random dogs:\", list_file_types('downloaded_data/random dogs'))\n",
    "#print(\"random cats:\", list_file_types('downloaded_data/random cats'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
