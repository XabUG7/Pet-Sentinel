{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "720ec52b-9fb0-4bd5-baf3-1d2701d16044",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change between \"cat\" and \"dog\" in the penultimate cell to evaluate both models precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4aa0a4-65f7-4a28-baeb-491a732f91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2406fe92-1900-4e9d-aa28-2b49e1a037d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_path = \"assets/transformed data/train_data_cat.pkl\"\n",
    "cat_test_path = \"assets/transformed data/test_data_cat.pkl\"\n",
    "dog_train_path = \"assets/transformed data/train_data_dog.pkl\"\n",
    "dog_test_path = \"assets/transformed data/test_data_dog.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5034183-4eed-4d0b-9568-39eecf371ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- MODEL ---------\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.features = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becece4b-80e3-467e-87d0-533de36baa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- EMBEDDING GENERATION ---------\n",
    "def save_gallery_embeddings(model, dataset_path, animal):\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    embeddings = []\n",
    "    \n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    data_label_1 = [item[0] for item in dataset if item[1] == 1]\n",
    "\n",
    "    for img_tensor_norm in data_label_1:\n",
    "        img_tensor = img_tensor_norm.unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            emb = model(img_tensor).cpu().numpy().flatten()\n",
    "            embeddings.append(emb)\n",
    "        \n",
    "    with open(f\"assets/embedding gallery/my_{animal}_gallery.pkl\", \"wb\") as f:\n",
    "        pickle.dump(np.array(embeddings), f)\n",
    "    print(\"Gallery embeddings saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5db0ab-8e7a-4aa9-b6db-40ac1de83a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- VERIFICATION ---------\n",
    "def verify_folder(model, dataset_path, gallery_path, threshold=0.75):\n",
    "    \n",
    "    with open(gallery_path, \"rb\") as f:\n",
    "        gallery = pickle.load(f)\n",
    "\n",
    "    with open(dataset_path, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    test_images = [item[0] for item in dataset]\n",
    "    true_labels = [item[1] for item in dataset]\n",
    "    predictions = []\n",
    "\n",
    "    match_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for img in test_images:\n",
    "        tensor = img.unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            emb = model(tensor).cpu().numpy().flatten()\n",
    "        score = np.mean(cosine_similarity([emb], gallery))\n",
    "        if score >= threshold:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "        \n",
    "    # Calculate precision and recall\n",
    "    precision = precision_score(true_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    \n",
    "    # print(f\"Precision: {precision:.2f}\")\n",
    "    # print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3c3437-a4c5-4229-a038-b52cd00bd28d",
   "metadata": {},
   "source": [
    "##### Change between cat and dog to verify the models with test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb86f13-3486-4eea-8852-c8639829bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gallery embeddings saved.\n"
     ]
    }
   ],
   "source": [
    "animal = \"dog\"\n",
    "\n",
    "\n",
    "if animal == \"cat\":\n",
    "    train_path = cat_train_path\n",
    "    test_path = cat_test_path\n",
    "\n",
    "elif animal == \"dog\":\n",
    "    train_path = dog_train_path\n",
    "    test_path = dog_test_path\n",
    "\n",
    "model = EmbeddingNet()\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(f\"assets/trained models/{animal}_model.pt\"))\n",
    "\n",
    "\n",
    "save_gallery_embeddings(model, train_path, animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e17dac9e-b253-4b96-bf4b-0e6f3ff422f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_folder(model, test_path, f\"assets/embedding gallery/my_{animal}_gallery.pkl\", threshold=0.85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
